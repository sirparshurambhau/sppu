import numpy as np

# Define the dataset
X1 = np.array([0, 1, 1, 0, 1, 1, 0])
X2 = np.array([1, 0, 0, 0, 1, 0, 1])
X3 = np.array([1, 0, 1, 1, 1, 1, 1])
Dk = np.array([1, 0, 1, 0, 1, 1, 0])

# Combine inputs into a 2D array
X = np.array([X1, X2, X3]).T

# Initialize weights and bias
weights = np.random.rand(3)
bias = np.random.rand()

# Define the activation function
def activate(net):
    return 1 if net >= 0 else -1

# Train the perceptron
learning_rate = 0.1
epochs = 1000

for epoch in range(epochs):
    for i in range(len(Dk)):
        net = np.dot(X[i], weights) + bias
        output = activate(net)
        error = Dk[i] - output
        weights += learning_rate * error * X[i]
        bias += learning_rate * error

# Test the perceptron on (1, 0, 0)
test_input = np.array([1, 0, 0])
test_output = activate(np.dot(test_input, weights) + bias)

print("Actual Output:", test_output)
